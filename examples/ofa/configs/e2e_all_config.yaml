# 基础配置
batch_size: 512
eval_batch_size: 256
dropout: 0.15
lr: 0.001
num_layers: 7
JK: "none"
task_names:
  - "cora_link"
  - "cora_node"

d_multiple:
  - 1.5
  - 2

d_min_ratio:
  - 1
  - 1

# LLM 相关配置
llm_name: 'sentence-transformers/multi-qa-distilbert-cos-v1'
checkpoint: 'saved_exp/2025-01-22 09:55:05.349660/lightning_logs/version_6/checkpoints/last.ckpt' 